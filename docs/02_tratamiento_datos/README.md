# Unidad 2: Manejo de datos con Pandas (orientado a APIs)

## 1. Introducci√≥n

**pandas** es la librer√≠a est√°ndar para manipulaci√≥n de datos en Python.  
Permite leer, limpiar, transformar y exportar datos f√°cilmente, y ser√° muy √∫til para preparar la informaci√≥n que serviremos desde nuestras APIs.

Estructuras principales:

- **Series** ‚Üí estructura 1D (como una lista con etiquetas).
- **DataFrame** ‚Üí estructura 2D (tabla con filas y columnas).

---

#### üîß Instalaci√≥n

> ‚öôÔ∏è _Nota:_ Si usas **Google Colab**, **Jupyter Notebook** o **Anaconda**, pandas ya est√° instalado.  
> Si trabajas desde **VS Code**, la terminal o un entorno virtual, inst√°lalo con:
>
> ```bash
> pip install pandas
> ```

---

## 2. Jupyter Notebook

Jupyter Notebook: entorno interactivo para trabajar con datos

**Jupyter Notebook** es una herramienta que permite escribir y ejecutar c√≥digo Python de forma interactiva, mezclando texto, c√≥digo y resultados en un mismo documento.  
Es el entorno m√°s usado en ciencia de datos y an√°lisis porque permite ir **probando paso a paso** el c√≥digo y **ver directamente las salidas de pandas** en forma de tabla.

---

#### üîπ Ventajas principales

- Ejecuci√≥n **celda a celda**, ideal para pruebas incrementales.
- Permite **documentar con texto y Markdown** el an√°lisis.
- Muestra los resultados de **gr√°ficos, tablas y outputs** directamente bajo cada celda.
- Perfecto para **experimentar, limpiar y explorar datos** antes de usarlos en una aplicaci√≥n o API.

---

#### üîπ Estructura b√°sica

Cada notebook se compone de **celdas**:

- Celdas de **c√≥digo** (donde se escribe Python).
- Celdas de **texto Markdown** (para explicaciones, t√≠tulos, listas, etc.).

Ejemplo:

```python
import pandas as pd

df = pd.DataFrame({
    "nombre": ["Ana", "Luis", "Marta"],
    "edad": [25, 30, 22]
})
df
```

> üí° En un notebook, al ejecutar esa celda, la tabla `DataFrame` se muestra de forma visual y formateada (m√°s agradable que en la consola).

---

#### üîπ C√≥mo instalar y ejecutar Jupyter Notebook

Si usas **Anaconda**, ya viene instalado.  
Si no, puedes instalarlo manualmente con:

```bash
pip install notebook
```

Luego se lanza desde la terminal con:

```bash
jupyter notebook
```

Esto abrir√° una pesta√±a en el navegador, normalmente en la direcci√≥n  
`http://localhost:8888`, desde donde puedes crear nuevos notebooks `.ipynb`.

---

#### üîπ Alternativas modernas

- **JupyterLab** ‚Üí versi√≥n m√°s avanzada con pesta√±as, paneles, explorador de archivos, etc.
- **VS Code** ‚Üí permite abrir y ejecutar notebooks directamente sin salir del editor.
- **Google Colab** ‚Üí entorno online gratuito (no requiere instalaci√≥n).

---

#### üîπ Usar Jupyter online (Google Colab)

**Google Colab** es una opci√≥n ideal para los alumnos que no quieren configurar nada localmente.  
Solo hace falta tener una cuenta de Google y acceder a:

üëâ [https://colab.research.google.com](https://colab.research.google.com)

Ventajas:

- No requiere instalaci√≥n.
- Permite guardar los notebooks en **Google Drive**.
- Ya trae **pandas**, **NumPy** y **matplotlib** instalados.
- Se pueden importar datasets directamente desde URLs o desde el Drive.

Ejemplo de carga de CSV desde URL:

```python
import pandas as pd

url = "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv"
df = pd.read_csv(url)
df.head()
```

---

#### üîπ Guardar y compartir notebooks

Los notebooks se guardan con extensi√≥n `.ipynb`.  
Pueden compartirse f√°cilmente:

- Por correo o Drive (como cualquier archivo).
- Export√°ndose a otros formatos: **HTML**, **PDF**, **Markdown**, etc.

```bash
jupyter nbconvert --to html mi_notebook.ipynb
```

---

> ‚öôÔ∏è **En resumen:**  
> Usa **Jupyter Notebook o Colab** para explorar y limpiar datos.  
> M√°s adelante, cuando construyas las APIs, trabajar√°s con los mismos scripts `.py` pero ya listos para producci√≥n.

---

## 3. Crear y cargar datos

```python
import pandas as pd

# Crear un DataFrame desde un diccionario
data = {
    "nombre": ["Ana", "Luis", "Marta"],
    "edad": [25, 30, 22],
    "ciudad": ["Madrid", "Sevilla", "Valencia"]
}
df = pd.DataFrame(data)
```

Tambi√©n podemos cargar datos desde distintos formatos:

```python
# Desde un CSV
df_csv = pd.read_csv("personas.csv")

# Desde un Excel
df_excel = pd.read_excel("personas.xlsx", sheet_name="Hoja1")

# Desde un JSON
df_json = pd.read_json("personas.json")

```

---

## 4. Selecci√≥n, filtrado y ordenaci√≥n.

```python
# Seleccionar una columna
nombres = df["nombre"]

# Filtrar por condici√≥n
mayores_25 = df[df["edad"] > 25]

# Seleccionar varias columnas
sub_df = df[["nombre", "ciudad"]]

# Seleccionar una fila por √≠ndice
fila_0 = df.loc[0]
```

---

### Agrupaciones y ordenaci√≥n

```python
# Media de edad por ciudad
print(df.groupby("ciudad")["edad"].mean())

# Ordenar por edad descendente
df_ordenado = df.sort_values(by="edad", ascending=False)
```

## 5. Exploraci√≥n y detecci√≥n de valores an√≥malos

### Exploraci√≥n r√°pida

```python
print(df.head())       # primeras filas
print(df.shape)        # dimensiones
print(df.columns)      # nombres de columnas
print(df.info())       # informaci√≥n general
print(df.describe())   # estad√≠sticas b√°sicas
```

### Detecci√≥n de valores an√≥malos

Antes de limpiar los datos, es recomendable **explorar su contenido** para detectar errores frecuentes:

- Valores duplicados o vac√≠os.
- Diferencias de formato (por ejemplo, may√∫sculas/min√∫sculas o espacios).
- Abreviaturas o nombres inconsistentes.
- Outliers (valores num√©ricos fuera de rango).

Una funci√≥n muy √∫til para inspeccionar el contenido de cada columna es `.unique()`:

```python
import pandas as pd

df = pd.read_csv("datos.csv")

# Mostrar los valores √∫nicos de las columnas categ√≥ricas
print(df["ciudad"].unique())
print(df["nombre"].unique())
```

Tambi√©n se pueden obtener estad√≠sticas r√°pidas con:

```python
df.describe(include="all")
```

Esto muestra recuentos, medias, m√≠nimos, m√°ximos y frecuencias m√°s comunes.  
A partir de aqu√≠, puedes decidir qu√© reglas aplicar en tu limpieza (por ejemplo, reemplazar abreviaturas o eliminar valores an√≥malos).

---

## 7. Limpieza de datos

```python
# Comprobar valores nulos
df.isna().sum()

# Eliminar filas con valores nulos
df = df.dropna()

# Rellenar nulos con la media de la columna
df["edad"] = df["edad"].fillna(df["edad"].mean())

# Eliminar duplicados
df = df.drop_duplicates()

# Normalizar texto
df["nombre"] = df["nombre"].str.strip().str.title()

# Conversi√≥n de tipos
df["edad"] = pd.to_numeric(df["edad"], errors="coerce")
df["fecha"] = pd.to_datetime(df.get("fecha"), errors="coerce")

# Reemplazar valores
df["ciudad"] = df["ciudad"].replace({"Mad": "Madrid", "Sev": "Sevilla"})
```

---

### Uso de expresiones regulares en la limpieza de datos

Las **expresiones regulares (regex)** son una herramienta muy potente para detectar o corregir patrones en texto.  
En pandas se pueden usar directamente con m√©todos como `.str.contains()` o `.str.replace()`.

Por ejemplo, para eliminar caracteres no alfab√©ticos de los nombres:

```python
df["nombre"] = df["nombre"].str.replace(r"[^a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë\s]", "", regex=True)
```

Para validar emails correctamente formados:

```python
df = df[df["email"].str.contains(r"^[\w\.-]+@[\w\.-]+\.\w+$", na=False)]
```

O para detectar filas donde el n√∫mero de tel√©fono no tenga 9 d√≠gitos:

```python
telefonos_erroneos = df[~df["telefono"].str.contains(r"^\d{9}$", na=False)]
print(telefonos_erroneos)
```

Las regex permiten automatizar muchas tareas de limpieza textual:

- Normalizaci√≥n de formatos (fechas, c√≥digos postales, tel√©fonos).
- Detecci√≥n de errores de escritura.
- Filtrado o eliminaci√≥n de datos inv√°lidos.

üí° Consejo: puedes probar tus expresiones regulares en sitios web como [regex101.com](https://regex101.com/) antes de aplicarlas en tu c√≥digo.

---

## 8. Guardar y exportar datos (CSV, Excel, JSON)

Una vez limpios los datos, es habitual guardarlos para su reutilizaci√≥n o para servirlos desde una API.

```python
# Guardar como CSV
df.to_csv("personas_limpias.csv", index=False)

# Guardar como Excel
df.to_excel("personas_limpias.xlsx", index=False, sheet_name="Datos")

# Guardar como JSON
df.to_json("personas_limpias.json", orient="records", indent=4, force_ascii=False)
```

üëâ En general:

- **CSV** ‚Üí formato m√°s universal y ligero.
- **Excel** ‚Üí pr√°ctico para informes o colaboraci√≥n.
- **JSON** ‚Üí ideal para APIs.

---

## 9. Preparar datos para API

Las APIs suelen devolver datos en formato **JSON**.  
Podemos convertir f√°cilmente un DataFrame en JSON o en una lista de diccionarios.

```python
# DataFrame ‚Üí lista de diccionarios
data_api = df.to_dict(orient="records")

# DataFrame ‚Üí cadena JSON
json_str = df.to_json(orient="records", indent=4, force_ascii=False)
```

Ejemplo pr√°ctico (usando FastAPI):

```python
from fastapi import FastAPI
from fastapi.responses import JSONResponse
import pandas as pd

app = FastAPI()

@app.get("/personas")
def obtener_personas():
    df = pd.read_csv("personas_limpias.csv")
    data = df.to_dict(orient="records")
    return JSONResponse(content=data)
```

---

## 10. Resumen del flujo para APIs

1. **Cargar datos** desde CSV, Excel o JSON.
2. **Explorar y limpiar**: eliminar duplicados, manejar nulos, normalizar texto y tipos.
3. **Filtrar o transformar** seg√∫n las necesidades del endpoint.
4. **Exportar o convertir** a JSON para devolver desde la API.

---
